{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+A0/hXzAJOC9VPMI4ZWON",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AntoineGaton/CTU/blob/main/Titanic%20Dataset%20Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "12zt5kSRK4Sk",
        "outputId": "4b4e6e76-feaf-485c-d79b-66be2822e84b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "╭──────────────────────────╮\n",
              "│ \u001b[1;36mTitanic Dataset Analysis\u001b[0m │\n",
              "╰──────────────────────────╯\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────╮\n",
              "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Titanic Dataset Analysis</span> │\n",
              "╰──────────────────────────╯\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;32mData loaded and preprocessed successfully!\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Data loaded and preprocessed successfully!</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;32mClustering completed!\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Clustering completed!</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "╭──────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
              "│ \u001b[3m                                        Cluster Description                                         \u001b[0m │\n",
              "│ ┏━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━┓ │\n",
              "│ ┃\u001b[1m \u001b[0m\u001b[1mPassengerId\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSurvived\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPclass\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Sex\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  Age\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSibSp\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mParch\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Fare\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mEmbarked_Q\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mEmbarked_S\u001b[0m\u001b[1m \u001b[0m┃ │\n",
              "│ ┡━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━┩ │\n",
              "│ │\u001b[36m \u001b[0m\u001b[36m     436.55\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m    0.30\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m  2.76\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m0.32\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m25.98\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m 0.56\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m 0.39\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m15.27\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m      0.12\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m      0.76\u001b[0m\u001b[36m \u001b[0m│ │\n",
              "│ │\u001b[36m \u001b[0m\u001b[36m     471.05\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m    0.61\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m  1.11\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m0.45\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m38.33\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m 0.41\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m 0.36\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m77.11\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m      0.01\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m      0.64\u001b[0m\u001b[36m \u001b[0m│ │\n",
              "│ └─────────────┴──────────┴────────┴──────┴───────┴───────┴───────┴───────┴────────────┴────────────┘ │\n",
              "╰──────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
              "│ <span style=\"font-style: italic\">                                        Cluster Description                                         </span> │\n",
              "│ ┏━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━┓ │\n",
              "│ ┃<span style=\"font-weight: bold\"> PassengerId </span>┃<span style=\"font-weight: bold\"> Survived </span>┃<span style=\"font-weight: bold\"> Pclass </span>┃<span style=\"font-weight: bold\">  Sex </span>┃<span style=\"font-weight: bold\">   Age </span>┃<span style=\"font-weight: bold\"> SibSp </span>┃<span style=\"font-weight: bold\"> Parch </span>┃<span style=\"font-weight: bold\">  Fare </span>┃<span style=\"font-weight: bold\"> Embarked_Q </span>┃<span style=\"font-weight: bold\"> Embarked_S </span>┃ │\n",
              "│ ┡━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━┩ │\n",
              "│ │<span style=\"color: #008080; text-decoration-color: #008080\">      436.55 </span>│<span style=\"color: #008080; text-decoration-color: #008080\">     0.30 </span>│<span style=\"color: #008080; text-decoration-color: #008080\">   2.76 </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> 0.32 </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> 25.98 </span>│<span style=\"color: #008080; text-decoration-color: #008080\">  0.56 </span>│<span style=\"color: #008080; text-decoration-color: #008080\">  0.39 </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> 15.27 </span>│<span style=\"color: #008080; text-decoration-color: #008080\">       0.12 </span>│<span style=\"color: #008080; text-decoration-color: #008080\">       0.76 </span>│ │\n",
              "│ │<span style=\"color: #008080; text-decoration-color: #008080\">      471.05 </span>│<span style=\"color: #008080; text-decoration-color: #008080\">     0.61 </span>│<span style=\"color: #008080; text-decoration-color: #008080\">   1.11 </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> 0.45 </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> 38.33 </span>│<span style=\"color: #008080; text-decoration-color: #008080\">  0.41 </span>│<span style=\"color: #008080; text-decoration-color: #008080\">  0.36 </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> 77.11 </span>│<span style=\"color: #008080; text-decoration-color: #008080\">       0.01 </span>│<span style=\"color: #008080; text-decoration-color: #008080\">       0.64 </span>│ │\n",
              "│ └─────────────┴──────────┴────────┴──────┴───────┴───────┴───────┴───────┴────────────┴────────────┘ │\n",
              "╰──────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;32mData split completed!\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Data split completed!</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "╭───────────────────────────╮\n",
              "│ \u001b[1mLogistic Regression Model\u001b[0m │\n",
              "╰───────────────────────────╯\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭───────────────────────────╮\n",
              "│ <span style=\"font-weight: bold\">Logistic Regression Model</span> │\n",
              "╰───────────────────────────╯\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Accuracy with Logistic Regression: \u001b[1;32m0.8045\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accuracy with Logistic Regression: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.8045</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "╭───────────────────────────────────────────────────────╮\n",
              "│ \u001b[3m    Classification Report for Logistic Regression    \u001b[0m │\n",
              "│ ┏━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━┓ │\n",
              "│ ┃\u001b[1m \u001b[0m\u001b[1mMetric \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPrecision\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mRecall\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mF1-Score\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSupport\u001b[0m\u001b[1m \u001b[0m┃ │\n",
              "│ ┡━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━┩ │\n",
              "│ │\u001b[36m \u001b[0m\u001b[36mClass 0\u001b[0m\u001b[36m \u001b[0m│      0.82 │   0.85 │     0.84 │   105.0 │ │\n",
              "│ │\u001b[36m \u001b[0m\u001b[36mClass 1\u001b[0m\u001b[36m \u001b[0m│      0.77 │   0.74 │     0.76 │    74.0 │ │\n",
              "│ └─────────┴───────────┴────────┴──────────┴─────────┘ │\n",
              "╰───────────────────────────────────────────────────────╯\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭───────────────────────────────────────────────────────╮\n",
              "│ <span style=\"font-style: italic\">    Classification Report for Logistic Regression    </span> │\n",
              "│ ┏━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━┓ │\n",
              "│ ┃<span style=\"font-weight: bold\"> Metric  </span>┃<span style=\"font-weight: bold\"> Precision </span>┃<span style=\"font-weight: bold\"> Recall </span>┃<span style=\"font-weight: bold\"> F1-Score </span>┃<span style=\"font-weight: bold\"> Support </span>┃ │\n",
              "│ ┡━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━┩ │\n",
              "│ │<span style=\"color: #008080; text-decoration-color: #008080\"> Class 0 </span>│      0.82 │   0.85 │     0.84 │   105.0 │ │\n",
              "│ │<span style=\"color: #008080; text-decoration-color: #008080\"> Class 1 </span>│      0.77 │   0.74 │     0.76 │    74.0 │ │\n",
              "│ └─────────┴───────────┴────────┴──────────┴─────────┘ │\n",
              "╰───────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "╭─────────────────────╮\n",
              "│ \u001b[1mRandom Forest Model\u001b[0m │\n",
              "╰─────────────────────╯\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────╮\n",
              "│ <span style=\"font-weight: bold\">Random Forest Model</span> │\n",
              "╰─────────────────────╯\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Accuracy with RandomForest: \u001b[1;32m0.8380\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accuracy with RandomForest: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.8380</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "╭───────────────────────────────────────────────────────╮\n",
              "│ \u001b[3m       Classification Report for Random Forest       \u001b[0m │\n",
              "│ ┏━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━┓ │\n",
              "│ ┃\u001b[1m \u001b[0m\u001b[1mMetric \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPrecision\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mRecall\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mF1-Score\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSupport\u001b[0m\u001b[1m \u001b[0m┃ │\n",
              "│ ┡━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━┩ │\n",
              "│ │\u001b[36m \u001b[0m\u001b[36mClass 0\u001b[0m\u001b[36m \u001b[0m│      0.84 │   0.90 │     0.87 │   105.0 │ │\n",
              "│ │\u001b[36m \u001b[0m\u001b[36mClass 1\u001b[0m\u001b[36m \u001b[0m│      0.84 │   0.76 │     0.79 │    74.0 │ │\n",
              "│ └─────────┴───────────┴────────┴──────────┴─────────┘ │\n",
              "╰───────────────────────────────────────────────────────╯\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭───────────────────────────────────────────────────────╮\n",
              "│ <span style=\"font-style: italic\">       Classification Report for Random Forest       </span> │\n",
              "│ ┏━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━┓ │\n",
              "│ ┃<span style=\"font-weight: bold\"> Metric  </span>┃<span style=\"font-weight: bold\"> Precision </span>┃<span style=\"font-weight: bold\"> Recall </span>┃<span style=\"font-weight: bold\"> F1-Score </span>┃<span style=\"font-weight: bold\"> Support </span>┃ │\n",
              "│ ┡━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━┩ │\n",
              "│ │<span style=\"color: #008080; text-decoration-color: #008080\"> Class 0 </span>│      0.84 │   0.90 │     0.87 │   105.0 │ │\n",
              "│ │<span style=\"color: #008080; text-decoration-color: #008080\"> Class 1 </span>│      0.84 │   0.76 │     0.79 │    74.0 │ │\n",
              "│ └─────────┴───────────┴────────┴──────────┴─────────┘ │\n",
              "╰───────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "'''\n",
        "Name: Antoine Gaton\n",
        "Date: October 13, 2024\n",
        "Course, CS491\n",
        "Description: Titanic Dataset Analysis utilizing KMeans for Unsupervised Learning and Logistic Regression and Random Forest for Supervised Learning.\n",
        "The goal was to experiment with different models in supervised learning to assess performance and explore potential improvements towards achieving 90% accuracy.\n",
        "'''\n",
        "\n",
        "# Importing necessary libraries\n",
        "import pandas as pd  # For data manipulation and analysis\n",
        "import numpy as np  # For numerical operations\n",
        "from sklearn.model_selection import train_test_split  # For splitting data into training and testing sets\n",
        "from sklearn.preprocessing import StandardScaler  # For standardizing features\n",
        "from sklearn.cluster import KMeans  # For K-means clustering\n",
        "from sklearn.ensemble import RandomForestClassifier  # For Random Forest classification\n",
        "from sklearn.linear_model import LogisticRegression  # For Logistic Regression\n",
        "from sklearn.metrics import accuracy_score, classification_report  # For model evaluation\n",
        "from rich.console import Console  # For enhanced console output\n",
        "from rich.table import Table  # For creating tables in the console\n",
        "from rich.panel import Panel  # For creating panels in the console\n",
        "\n",
        "# Create a Console object for rich output\n",
        "console = Console()\n",
        "\n",
        "def load_and_preprocess_data(url):\n",
        "    \"\"\"\n",
        "    Load the Titanic dataset and preprocess it for analysis.\n",
        "\n",
        "    This function performs several data cleaning and preprocessing steps:\n",
        "    1. Load the data from a URL\n",
        "    2. Remove irrelevant columns\n",
        "    3. Handle missing values\n",
        "    4. Encode categorical variables\n",
        "    \"\"\"\n",
        "    # Load the dataset from the URL\n",
        "    data = pd.read_csv(url)\n",
        "\n",
        "    # Drop columns that are not useful for our analysis\n",
        "    data = data.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "    # Fill missing values in the 'Age' column with the median age\n",
        "    data['Age'] = data['Age'].fillna(data['Age'].median())\n",
        "\n",
        "    # Fill missing values in the 'Embarked' column with the most common value\n",
        "    data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
        "\n",
        "    # Convert 'Sex' to numerical values (0 for male, 1 for female)\n",
        "    data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "    # Create dummy variables for 'Embarked' column (one-hot encoding)\n",
        "    data = pd.get_dummies(data, columns=['Embarked'], drop_first=True)\n",
        "\n",
        "    return data\n",
        "\n",
        "def perform_clustering(data):\n",
        "    \"\"\"\n",
        "    Perform K-means clustering on the dataset.\n",
        "\n",
        "    This function:\n",
        "    1. Standardizes the features\n",
        "    2. Applies K-means clustering with 2 clusters\n",
        "    3. Adds the cluster labels to the dataset\n",
        "    \"\"\"\n",
        "    # Standardize the features (important for K-means)\n",
        "    scaler = StandardScaler()\n",
        "    scaled_data = scaler.fit_transform(data.drop(columns=['Survived']))\n",
        "\n",
        "    # Perform K-means clustering with 2 clusters\n",
        "    kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "    data['Cluster'] = kmeans.fit_predict(scaled_data)\n",
        "\n",
        "    return data\n",
        "\n",
        "def describe_clusters(data):\n",
        "    \"\"\"\n",
        "    Describe the clusters by showing the mean values of features for each cluster.\n",
        "\n",
        "    This function creates a table to display the cluster descriptions.\n",
        "    \"\"\"\n",
        "    # Calculate mean values for each cluster\n",
        "    cluster_description = data.groupby('Cluster').mean()\n",
        "\n",
        "    # Create a table to display the cluster description\n",
        "    table = Table(title=\"Cluster Description\")\n",
        "\n",
        "    # Add columns to the table\n",
        "    for column in cluster_description.columns:\n",
        "        table.add_column(column, justify=\"right\", style=\"cyan\", no_wrap=True)\n",
        "\n",
        "    # Add rows to the table\n",
        "    for index, row in cluster_description.iterrows():\n",
        "        table.add_row(*[f\"{value:.2f}\" for value in row])\n",
        "\n",
        "    # Print the table in a panel\n",
        "    console.print(Panel(table, expand=False))\n",
        "\n",
        "def split_data(data):\n",
        "    \"\"\"\n",
        "    Split the data into features (X) and target variable (y),\n",
        "    then further split into training and testing sets.\n",
        "    \"\"\"\n",
        "    # Separate features (X) and target variable (y)\n",
        "    X = data.drop(columns=['Survived', 'Cluster'])\n",
        "    y = data['Survived']\n",
        "\n",
        "    # Split data into training (80%) and testing (20%) sets\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "def logistic_regression_model(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Train a Logistic Regression model, make predictions, and display the results.\n",
        "\n",
        "    This function:\n",
        "    1. Trains a Logistic Regression model\n",
        "    2. Makes predictions on the test set\n",
        "    3. Calculates and displays the accuracy and classification report\n",
        "    \"\"\"\n",
        "    # Create and train the Logistic Regression model\n",
        "    log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "    log_reg.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred_log_reg = log_reg.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
        "\n",
        "    # Generate classification report\n",
        "    report_log_reg = classification_report(y_test, y_pred_log_reg, output_dict=True)\n",
        "\n",
        "    # Display results\n",
        "    console.print(Panel(\"[bold]Logistic Regression Model[/bold]\", expand=False))\n",
        "    console.print(f\"Accuracy with Logistic Regression: [green]{accuracy_log_reg:.4f}[/green]\")\n",
        "\n",
        "    # Create a table for the classification report\n",
        "    table = Table(title=\"Classification Report for Logistic Regression\")\n",
        "    table.add_column(\"Metric\", style=\"cyan\")\n",
        "    table.add_column(\"Precision\", justify=\"right\")\n",
        "    table.add_column(\"Recall\", justify=\"right\")\n",
        "    table.add_column(\"F1-Score\", justify=\"right\")\n",
        "    table.add_column(\"Support\", justify=\"right\")\n",
        "\n",
        "    # Add rows to the table\n",
        "    for class_name, metrics in report_log_reg.items():\n",
        "        if class_name in ['0', '1']:\n",
        "            table.add_row(\n",
        "                f\"Class {class_name}\",\n",
        "                f\"{metrics['precision']:.2f}\",\n",
        "                f\"{metrics['recall']:.2f}\",\n",
        "                f\"{metrics['f1-score']:.2f}\",\n",
        "                str(metrics['support'])\n",
        "            )\n",
        "\n",
        "    # Print the table\n",
        "    console.print(Panel(table, expand=False))\n",
        "\n",
        "def random_forest_model(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Train a Random Forest model, make predictions, and display the results.\n",
        "\n",
        "    This function:\n",
        "    1. Trains a Random Forest model\n",
        "    2. Makes predictions on the test set\n",
        "    3. Calculates and displays the accuracy and classification report\n",
        "    \"\"\"\n",
        "    # Create and train the Random Forest model\n",
        "    classifier = RandomForestClassifier(random_state=42)\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred_rf = classifier.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "    # Generate classification report\n",
        "    report_rf = classification_report(y_test, y_pred_rf, output_dict=True)\n",
        "\n",
        "    # Display results\n",
        "    console.print(Panel(\"[bold]Random Forest Model[/bold]\", expand=False))\n",
        "    console.print(f\"Accuracy with RandomForest: [green]{accuracy_rf:.4f}[/green]\")\n",
        "\n",
        "    # Create a table for the classification report\n",
        "    table = Table(title=\"Classification Report for Random Forest\")\n",
        "    table.add_column(\"Metric\", style=\"cyan\")\n",
        "    table.add_column(\"Precision\", justify=\"right\")\n",
        "    table.add_column(\"Recall\", justify=\"right\")\n",
        "    table.add_column(\"F1-Score\", justify=\"right\")\n",
        "    table.add_column(\"Support\", justify=\"right\")\n",
        "\n",
        "    # Add rows to the table\n",
        "    for class_name, metrics in report_rf.items():\n",
        "        if class_name in ['0', '1']:\n",
        "            table.add_row(\n",
        "                f\"Class {class_name}\",\n",
        "                f\"{metrics['precision']:.2f}\",\n",
        "                f\"{metrics['recall']:.2f}\",\n",
        "                f\"{metrics['f1-score']:.2f}\",\n",
        "                str(metrics['support'])\n",
        "            )\n",
        "\n",
        "    # Print the table in a panel\n",
        "    console.print(Panel(table, expand=False))\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to orchestrate the Titanic dataset analysis.\n",
        "\n",
        "    This function:\n",
        "    1. Loads and preprocesses the data\n",
        "    2. Performs clustering\n",
        "    3. Splits the data into training and testing sets\n",
        "    4. Trains and evaluates Logistic Regression and Random Forest models\n",
        "    \"\"\"\n",
        "    console.print(Panel(\"[bold cyan]Titanic Dataset Analysis[/bold cyan]\", expand=False))\n",
        "\n",
        "    # URL of the Titanic dataset\n",
        "    url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "\n",
        "    # Load and preprocess the data\n",
        "    with console.status(\"[bold green]Loading and preprocessing data...[/bold green]\"):\n",
        "        data = load_and_preprocess_data(url)\n",
        "    console.print(\"[bold green]Data loaded and preprocessed successfully![/bold green]\")\n",
        "\n",
        "    # Perform clustering\n",
        "    with console.status(\"[bold green]Performing clustering...[/bold green]\"):\n",
        "        data = perform_clustering(data)\n",
        "    console.print(\"[bold green]Clustering completed![/bold green]\")\n",
        "\n",
        "    # Describe the clusters\n",
        "    describe_clusters(data)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    with console.status(\"[bold green]Splitting data for model training...[/bold green]\"):\n",
        "        X_train, X_test, y_train, y_test = split_data(data)\n",
        "    console.print(\"[bold green]Data split completed![/bold green]\")\n",
        "\n",
        "    # Train and evaluate the Logistic Regression model\n",
        "    logistic_regression_model(X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # Train and evaluate the Random Forest model\n",
        "    random_forest_model(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# This is a common Python idiom that checks if this script is being run directly\n",
        "# (as opposed to being imported as a module). If so, it calls the main() function.\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}