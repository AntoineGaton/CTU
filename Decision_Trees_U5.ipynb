{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMS9HMzSA4qwySJ5eopLZR1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AntoineGaton/CTU/blob/main/Decision_Trees_U5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "JKFlT0XHhfNc",
        "outputId": "768a8e79-f1f9-460e-a01c-ee8b83adf19b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "╔═══════════════════════════════════════════════ Information Gain ════════════════════════════════════════════════╗\n",
              "║ \u001b[32mInformation Gain:\u001b[0m 0.01785766632373198                                                                           ║\n",
              "║ \u001b[33mThis information gain is relatively low, suggesting only a modest improvement in purity.\u001b[0m                        ║\n",
              "╚═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╔═══════════════════════════════════════════════ Information Gain ════════════════════════════════════════════════╗\n",
              "║ <span style=\"color: #008000; text-decoration-color: #008000\">Information Gain:</span> 0.01785766632373198                                                                           ║\n",
              "║ <span style=\"color: #808000; text-decoration-color: #808000\">This information gain is relatively low, suggesting only a modest improvement in purity.</span>                        ║\n",
              "╚═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "╔═════════════════════════════════════════════════ Gini Impurity ═════════════════════════════════════════════════╗\n",
              "║ \u001b[32mGini Impurity:\u001b[0m 0.6624                                                                                           ║\n",
              "║ \u001b[33mModerate Gini impurity suggests some mix of classes in this node.\u001b[0m                                               ║\n",
              "╚═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╔═════════════════════════════════════════════════ Gini Impurity ═════════════════════════════════════════════════╗\n",
              "║ <span style=\"color: #008000; text-decoration-color: #008000\">Gini Impurity:</span> 0.6624                                                                                           ║\n",
              "║ <span style=\"color: #808000; text-decoration-color: #808000\">Moderate Gini impurity suggests some mix of classes in this node.</span>                                               ║\n",
              "╚═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "╔════════════════════════════════════════════════ Chi-Square Test ════════════════════════════════════════════════╗\n",
              "║ \u001b[32mChi-Square Statistic:\u001b[0m 150.0                                                                                     ║\n",
              "║ \u001b[32mP-value:\u001b[0m 2.035764090974152e-31                                                                                  ║\n",
              "║ \u001b[33mThe low p-value indicates a statistically significant association between the feature and the target.\u001b[0m           ║\n",
              "╚═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╔════════════════════════════════════════════════ Chi-Square Test ════════════════════════════════════════════════╗\n",
              "║ <span style=\"color: #008000; text-decoration-color: #008000\">Chi-Square Statistic:</span> 150.0                                                                                     ║\n",
              "║ <span style=\"color: #008000; text-decoration-color: #008000\">P-value:</span> 2.035764090974152e-31                                                                                  ║\n",
              "║ <span style=\"color: #808000; text-decoration-color: #808000\">The low p-value indicates a statistically significant association between the feature and the target.</span>           ║\n",
              "╚═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "╔═════════════════════════════════════════════ Reduction in Variance ═════════════════════════════════════════════╗\n",
              "║ \u001b[32mReduction in Variance:\u001b[0m 0.0                                                                                      ║\n",
              "║ \u001b[33mA reduction in variance of zero indicates no improvement in homogeneity from this split.\u001b[0m                        ║\n",
              "╚═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╔═════════════════════════════════════════════ Reduction in Variance ═════════════════════════════════════════════╗\n",
              "║ <span style=\"color: #008000; text-decoration-color: #008000\">Reduction in Variance:</span> 0.0                                                                                      ║\n",
              "║ <span style=\"color: #808000; text-decoration-color: #808000\">A reduction in variance of zero indicates no improvement in homogeneity from this split.</span>                        ║\n",
              "╚═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "╔════════════════════════════════════════════════════ Summary ════════════════════════════════════════════════════╗\n",
              "║ \u001b[1;35mSummary of Results\u001b[0m                                                                                              ║\n",
              "║ The classification criteria suggest:                                                                            ║\n",
              "║ - Information Gain and Gini Impurity indicate the purity levels after a split.                                  ║\n",
              "║ - Chi-Square results show the statistical association between features and the target variable.                 ║\n",
              "║ The regression criterion (Reduction in Variance) assesses the effectiveness of the split in homogenizing target ║\n",
              "║ values in regression.                                                                                           ║\n",
              "╚═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╔════════════════════════════════════════════════════ Summary ════════════════════════════════════════════════════╗\n",
              "║ <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Summary of Results</span>                                                                                              ║\n",
              "║ The classification criteria suggest:                                                                            ║\n",
              "║ - Information Gain and Gini Impurity indicate the purity levels after a split.                                  ║\n",
              "║ - Chi-Square results show the statistical association between features and the target variable.                 ║\n",
              "║ The regression criterion (Reduction in Variance) assesses the effectiveness of the split in homogenizing target ║\n",
              "║ values in regression.                                                                                           ║\n",
              "╚═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\"\"\"\n",
        "Author: Antoine Gaton\n",
        "Date: November 10, 2024\n",
        "Course: Machine Learning: CS379\n",
        "Description: This code implements four different splitting approaches for decision trees:\n",
        "1. Reduction in Variance (for regression).\n",
        "2. Information Gain (for classification).\n",
        "3. Gini Impurity (for classification).\n",
        "4. Chi-Square Test (for classification).\n",
        "\n",
        "The code showcases each approach with a sample dataset and is structured for\n",
        "modular use and extensibility.\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.datasets import load_iris, fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from math import log2\n",
        "from scipy.stats import chi2_contingency\n",
        "from rich import print\n",
        "from rich.console import Console\n",
        "from rich.panel import Panel\n",
        "from rich.box import DOUBLE\n",
        "\n",
        "console = Console()\n",
        "\n",
        "def reduction_in_variance(y):\n",
        "    \"\"\"\n",
        "    Reduction in variance splitting criterion.\n",
        "\n",
        "    Parameters:\n",
        "    - y: array-like, target values\n",
        "\n",
        "    Returns:\n",
        "    - variance_reduction: float, amount of variance reduction achieved\n",
        "    \"\"\"\n",
        "    try:\n",
        "        initial_variance = np.var(y)\n",
        "        if len(y) <= 1:\n",
        "            return 0  # Edge case for no or single data point\n",
        "        return initial_variance - np.var(y)\n",
        "    except Exception as e:\n",
        "        console.print(f\"[red]Error in reduction_in_variance: {e}[/red]\")\n",
        "        return 0\n",
        "\n",
        "\n",
        "def information_gain(y, y_left, y_right):\n",
        "    \"\"\"\n",
        "    Information gain splitting criterion based on entropy.\n",
        "\n",
        "    Parameters:\n",
        "    - y: array-like, target values\n",
        "    - y_left: array-like, left split\n",
        "    - y_right: array-like, right split\n",
        "\n",
        "    Returns:\n",
        "    - info_gain: float, amount of information gained\n",
        "    \"\"\"\n",
        "    try:\n",
        "        def entropy(vals):\n",
        "            probs = np.bincount(vals) / len(vals)\n",
        "            return -sum(p * log2(p) for p in probs if p > 0)\n",
        "\n",
        "        entropy_before = entropy(y)\n",
        "        entropy_after = (len(y_left) / len(y)) * entropy(y_left) + (len(y_right) / len(y)) * entropy(y_right)\n",
        "        return entropy_before - entropy_after\n",
        "    except Exception as e:\n",
        "        console.print(f\"[red]Error in information_gain: {e}[/red]\")\n",
        "        return 0\n",
        "\n",
        "\n",
        "def gini_impurity(y):\n",
        "    \"\"\"\n",
        "    Gini impurity splitting criterion.\n",
        "\n",
        "    Parameters:\n",
        "    - y: array-like, target values\n",
        "\n",
        "    Returns:\n",
        "    - gini: float, gini impurity value\n",
        "    \"\"\"\n",
        "    try:\n",
        "        probs = np.bincount(y) / len(y)\n",
        "        return 1 - sum(p**2 for p in probs)\n",
        "    except Exception as e:\n",
        "        console.print(f\"[red]Error in gini_impurity: {e}[/red]\")\n",
        "        return 0\n",
        "\n",
        "\n",
        "def chi_square_test(y, y_pred):\n",
        "    \"\"\"\n",
        "    Chi-square test splitting criterion.\n",
        "\n",
        "    Parameters:\n",
        "    - y: array-like, true target values\n",
        "    - y_pred: array-like, predicted target values\n",
        "\n",
        "    Returns:\n",
        "    - chi2: float, chi-square statistic\n",
        "    - p: float, p-value\n",
        "    \"\"\"\n",
        "    try:\n",
        "        contingency_table = np.zeros((len(np.unique(y)), len(np.unique(y_pred))))\n",
        "        for i, label in enumerate(np.unique(y)):\n",
        "            for j, pred in enumerate(np.unique(y_pred)):\n",
        "                contingency_table[i, j] = np.sum((y == label) & (y_pred == pred))\n",
        "        chi2, p, _, _ = chi2_contingency(contingency_table)\n",
        "        return chi2, p\n",
        "    except Exception as e:\n",
        "        console.print(f\"[red]Error in chi_square_test: {e}[/red]\")\n",
        "        return 0, 1\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to demonstrate each splitting criterion.\n",
        "    \"\"\"\n",
        "    # Load datasets\n",
        "    iris = load_iris()\n",
        "    cali_housing = fetch_california_housing()\n",
        "\n",
        "    # Sample data for classification (Iris) and regression (California Housing)\n",
        "    X_class, _, y_class, _ = train_test_split(iris.data, iris.target, test_size=0.5, random_state=42)\n",
        "    X_reg, _, y_reg, _ = train_test_split(cali_housing.data, cali_housing.target, test_size=0.5, random_state=42)\n",
        "\n",
        "    # Information Gain and Explanation\n",
        "    ig = information_gain(y_class, y_class[:len(y_class)//2], y_class[len(y_class)//2:])\n",
        "    ig_text = f\"[green]Information Gain:[/green] {ig}\\n\"\n",
        "    if ig > 0.1:\n",
        "        ig_text += \"[yellow]This information gain is relatively high, indicating a significant improvement in purity.[/yellow]\"\n",
        "    else:\n",
        "        ig_text += \"[yellow]This information gain is relatively low, suggesting only a modest improvement in purity.[/yellow]\"\n",
        "    console.print(Panel(ig_text, title=\"Information Gain\", box=DOUBLE))\n",
        "\n",
        "    # Gini Impurity and Explanation\n",
        "    gini = gini_impurity(y_class)\n",
        "    gini_text = f\"[green]Gini Impurity:[/green] {gini}\\n\"\n",
        "    if gini < 0.3:\n",
        "        gini_text += \"[yellow]Low Gini impurity indicates a relatively pure node.[/yellow]\"\n",
        "    elif gini < 0.7:\n",
        "        gini_text += \"[yellow]Moderate Gini impurity suggests some mix of classes in this node.[/yellow]\"\n",
        "    else:\n",
        "        gini_text += \"[yellow]High Gini impurity indicates a mixed node with multiple classes.[/yellow]\"\n",
        "    console.print(Panel(gini_text, title=\"Gini Impurity\", box=DOUBLE))\n",
        "\n",
        "    # Chi-Square Test and Explanation\n",
        "    chi2, p_val = chi_square_test(y_class, y_class)\n",
        "    chi2_text = f\"[green]Chi-Square Statistic:[/green] {chi2}\\n[green]P-value:[/green] {p_val}\\n\"\n",
        "    if p_val < 0.05:\n",
        "        chi2_text += \"[yellow]The low p-value indicates a statistically significant association between the feature and the target.[/yellow]\"\n",
        "    else:\n",
        "        chi2_text += \"[yellow]The high p-value suggests no significant association between the feature and the target.[/yellow]\"\n",
        "    console.print(Panel(chi2_text, title=\"Chi-Square Test\", box=DOUBLE))\n",
        "\n",
        "    # Reduction in Variance and Explanation\n",
        "    variance_reduction = reduction_in_variance(y_reg)\n",
        "    variance_text = f\"[green]Reduction in Variance:[/green] {variance_reduction}\\n\"\n",
        "    if variance_reduction > 0:\n",
        "        variance_text += \"[yellow]This reduction in variance suggests that the split improves the homogeneity of the target values.[/yellow]\"\n",
        "    else:\n",
        "        variance_text += \"[yellow]A reduction in variance of zero indicates no improvement in homogeneity from this split.[/yellow]\"\n",
        "    console.print(Panel(variance_text, title=\"Reduction in Variance\", box=DOUBLE))\n",
        "\n",
        "    # Summary\n",
        "    summary_text = (\n",
        "        \"[bold magenta]Summary of Results[/bold magenta]\\n\"\n",
        "        \"The classification criteria suggest:\\n\"\n",
        "        \"- Information Gain and Gini Impurity indicate the purity levels after a split.\\n\"\n",
        "        \"- Chi-Square results show the statistical association between features and the target variable.\\n\"\n",
        "        \"The regression criterion (Reduction in Variance) assesses the effectiveness of the split in homogenizing target values in regression.\"\n",
        "    )\n",
        "    console.print(Panel(summary_text, title=\"Summary\", box=DOUBLE))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}